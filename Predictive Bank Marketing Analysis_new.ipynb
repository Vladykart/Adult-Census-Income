{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question: Bank Marketing Analysis\n",
    "Attached is a txt file containing some real data that relates to a marketing campaign run by\n",
    "a bank. The aim of the marketing campaign was to get customers to subscribe to a bank\n",
    "term deposit product. Whether they did this or not is variable ‘y’ in the data set.\n",
    "The bank in question is considering how to optimise this campaign in future.\n",
    "What would your recommendations to the marketing manager be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variable description\n",
    "\n",
    "The variables are as follows: </br>\n",
    "Input variables: 1 - age (numeric)</br>\n",
    "2 - job : type of job (categorical:\n",
    "'admin.','unknown','unemployed','management','housemaid',</br>\n",
    "'entrepreneur','student','blue-collar','self-employed',</br>\n",
    "'retired','technician','services')</br>\n",
    "3 - marital : marital status </br>\n",
    "(categorical: 'married','divorced','single'; note:</br>\n",
    " 'divorced' means divorced or widowed)\n",
    "4 -education (categorical: 'unknown','secondary','primary','tertiary')</br>\n",
    "5 - default: has credit in\n",
    "default? (binary: 'yes','no') </br>\n",
    "6 - balance: average yearly balance, in euros (numeric)</br>\n",
    "7 - housing: has housing loan? (binary: 'yes','no') </br>\n",
    "8 - loan: has personal loan? (binary:\n",
    "'yes','no') ### related with the last contact of the current campaign:</br>\n",
    "9 - contact: contact\n",
    "communication type (categorical: 'unknown','telephone','cellular')</br>\n",
    " 10 - day: last contact\n",
    "day of the month (numeric)</br>\n",
    " 11 - month: last contact month of year (categorical: 'jan', 'feb',\n",
    "'mar', ..., 'nov', 'dec')</br>\n",
    " 12 - duration: last contact duration, in seconds (numeric) #### other\n",
    "attributes:</br>\n",
    " 13 - campaign: number of contacts performed during this campaign and for this\n",
    "client (numeric, includes last contact)</br>\n",
    " 14 - pdays: number of days that passed by after the\n",
    "client was last contacted from a previous campaign (numeric, -1 means client was not\n",
    "previously contacted)</br>\n",
    " 15 - previous: number of contacts performed before this campaign\n",
    "and for this client (numeric)</br>\n",
    " 16 - poutcome: outcome of the previous marketing campaign\n",
    "(categorical: 'unknown','other','failure','success')\n",
    "Output variable (desired target):</br>\n",
    " 17 - y - has the client subscribed a term deposit? (binary:\n",
    "'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1.  Data cleansing and missing value treatment</br>\n",
    "\n",
    "2.  Exploratory data analysis and visual plotting</br>\n",
    "\n",
    "3.  The scope of feature engineering</br>\n",
    "\n",
    "4.  Model building and evaluation,</br>\n",
    "\n",
    "please choose a different set of models to show different</br>\n",
    "prediction accuracy that you get from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing and displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandasgui'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2072/960044561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandasgui\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandasgui'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandasgui import show\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import gc\n",
    "import warnings\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, confusion_matrix, precision_score, auc, \\\n",
    "    recall_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.txt\", delim_whitespace=True)\n",
    "print(data.shape)\n",
    "data.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exploiratory Data Analysis\n",
    "# categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "deposit=data['y'].value_counts()\n",
    "deposit.plot(kind='bar')\n",
    "plt.title('Ratio of acceptance and rejection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Given data set is highly imbalanced, i.e. number of data belonging to 'no' category is way higher than 'yes' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ageyes=data['age'][data.y=='yes']\n",
    "ageno=data['age'][data.y=='no']\n",
    "plt.figure(facecolor='w')\n",
    "ageyes.plot(kind='hist',color='green')\n",
    "plt.title('Age Distrubution Accepted Customer')\n",
    "plt.figure(facecolor='w')\n",
    "ageno.plot(kind='hist',color='gray')\n",
    "plt.title('Age Distrubution Rejected Customer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# function that show categorical values dist\n",
    "\n",
    "def plot_bar(data ,column):\n",
    "\n",
    "    temp_1 = pd.DataFrame()\n",
    "    temp_1['No'] = data[data['y'] == 'no'][column].value_counts()\n",
    "    temp_1['Yes'] = data[data['y'] == 'yes'][column].value_counts()\n",
    "    plt.figure(facecolor='w')\n",
    "    temp_1.plot(kind='bar')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Number of clients')\n",
    "    plt.title('Distribution of {} and deposit'.format(column))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_bar(data ,'job'),\\\n",
    "plot_bar(data,'marital'),\\\n",
    "plot_bar(data, 'education'),\\\n",
    "plot_bar(data,'contact'),\\\n",
    "plot_bar(data,'loan'),\\\n",
    "plot_bar(data,'housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert target variable into numeric\n",
    "# data.y = data.y.map({'no':0, 'yes':1}).astype('uint8')\n",
    "data_new = pd.get_dummies(data, columns=['job','marital',\n",
    "                                         'education','default',\n",
    "                                         'housing','loan',\n",
    "                                         'contact','month',\n",
    "                                         'poutcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TODO:\n",
    "ADD day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2014\tсуббота 10 май 2014 г.\tмай\t+ 9 months\t1 time in year 2014\n",
    "# суббота 17 май 2014 г.\tмай\t+ 9 months\t1 time in year 2014\n",
    "# so lets set year as 2014\n",
    "data.day.unique()\n",
    "# pd.to_datetime(str(f'{data.month} {str(data.day)}, 2014'), format=\"%b %d, %Y\")\n",
    "# data['dates'] = pd.to_datetime(str('2014-'+str(data.month)+'-'+str(data.day)), format=\"%Y-%b-%d\" )\n",
    "# data['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data[data['y'] == 'yes']\n",
    "data2 = data[data['y'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "# b1 = ax[0, 0].bar(data1['day_of_week'].unique(),height = data1['day_of_week'].value_counts(),color='#000000')\n",
    "# b2 = ax[0, 0].bar(data2['day_of_week'].unique(),height = data2['day_of_week'].value_counts(),bottom = data1['day_of_week'].value_counts(),color = '#DC4405')\n",
    "# ax[0, 0].title.set_text('Day of week')\n",
    "# #ax[0, 0].legend((b1[0], b2[0]), ('Yes', 'No'))\n",
    "b1 = ax[0, 1].bar(data1['month'].unique(),height = data1['month'].value_counts(),color='#000000')\n",
    "b2 = ax[0, 1].bar(data2['month'].unique(),height = data2['month'].value_counts(),bottom = data1['month'].value_counts(),color = '#DC4405')\n",
    "ax[0, 1].title.set_text('Month')\n",
    "ax[1, 0].bar(data1['job'].unique(),height = data1['job'].value_counts(),color='#000000')\n",
    "ax[1, 0].bar(data1['job'].unique(),height = data2['job'].value_counts()[data1['job'].value_counts().index],bottom = data1['job'].value_counts(),color = '#DC4405')\n",
    "ax[1, 0].title.set_text('Type of Job')\n",
    "ax[1, 0].tick_params(axis='x',rotation=90)\n",
    "ax[1, 1].bar(data1['education'].unique(),height = data1['education'].value_counts(),color='#000000') #row=0, col=1\n",
    "ax[1, 1].bar(data1['education'].unique(),height = data2['education'].value_counts()[data1['education'].value_counts().index],bottom = data1['education'].value_counts(),color = '#DC4405')\n",
    "ax[1, 1].title.set_text('Education')\n",
    "ax[1, 1].tick_params(axis='x',rotation=90)\n",
    "#ax[0, 1].xticks(rotation=90)\n",
    "plt.figlegend((b1[0], b2[0]), ('Yes', 'No'),loc=\"right\",title = \"Term deposit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(15,10))\n",
    "\n",
    "b1 = ax[0, 0].bar(data1['marital'].unique(),height = data1['marital'].value_counts(),color='#000000')\n",
    "b2 = ax[0, 0].bar(data1['marital'].unique(),height = data2['marital'].value_counts()[data1['marital'].value_counts().index],bottom = data1['marital'].value_counts(),color = '#DC4405')\n",
    "ax[0, 0].title.set_text('Marital Status')\n",
    "#ax[0, 0].legend((b1[0], b2[0]), ('Yes', 'No'))\n",
    "ax[0, 1].bar(data1['housing'].unique(),height = data1['housing'].value_counts(),color='#000000')\n",
    "ax[0, 1].bar(data1['housing'].unique(),height = data2['housing'].value_counts()[data1['housing'].value_counts().index],bottom = data1['housing'].value_counts(),color = '#DC4405')\n",
    "ax[0, 1].title.set_text('Has housing loan')\n",
    "ax[0, 2].bar(data1['loan'].unique(),height = data1['loan'].value_counts(),color='#000000')\n",
    "ax[0, 2].bar(data1['loan'].unique(),height = data2['loan'].value_counts()[data1['loan'].value_counts().index],bottom = data1['loan'].value_counts(),color = '#DC4405')\n",
    "ax[0, 2].title.set_text('Has personal loan')\n",
    "ax[1, 0].bar(data1['contact'].unique(),height = data1['contact'].value_counts(),color='#000000')\n",
    "ax[1, 0].bar(data1['contact'].unique(),height = data2['contact'].value_counts()[data1['contact'].value_counts().index],bottom = data1['contact'].value_counts(),color = '#DC4405')\n",
    "ax[1, 0].title.set_text('Type of Contact')\n",
    "ax[1, 1].bar(data1['default'].unique(),height = data1['default'].value_counts(),color='#000000')\n",
    "ax[1, 1].bar(data1['default'].unique(),height = data2['default'].value_counts()[data1['default'].value_counts().index],bottom = data1['default'].value_counts(),color = '#DC4405')\n",
    "ax[1, 1].title.set_text('Has credit in default')\n",
    "ax[1, 2].bar(data1['poutcome'].unique(),height = data1['poutcome'].value_counts(),color='#000000')\n",
    "ax[1, 2].bar(data1['poutcome'].unique(),height = data2['poutcome'].value_counts()[data1['poutcome'].value_counts().index],bottom = data1['poutcome'].value_counts(),color = '#DC4405')\n",
    "ax[1, 2].title.set_text('Outcome of the previous marketing campaign')\n",
    "plt.figlegend((b1[0], b2[0]), ('Yes', 'No'),loc=\"right\",title = \"Term deposit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,10))\n",
    "\n",
    "ax[0, 0].hist(data2['age'],color = '#DC4405',alpha=0.7,bins=20, edgecolor='white')\n",
    "ax[0, 0].hist(data1['age'],color='#000000',alpha=0.5,bins=20, edgecolor='white')\n",
    "ax[0, 0].title.set_text('Age')\n",
    "ax[0, 1].hist(data2['duration'],color = '#DC4405',alpha=0.7, edgecolor='white')\n",
    "ax[0, 1].hist(data1['duration'],color='#000000',alpha=0.5, edgecolor='white')\n",
    "ax[0, 1].title.set_text('Contact duration')\n",
    "ax[1, 0].hist(data2['campaign'],color = '#DC4405',alpha=0.7, edgecolor='white')\n",
    "ax[1, 0].hist(data1['campaign'],color='#000000',alpha=0.5, edgecolor='white')\n",
    "ax[1, 0].title.set_text('Number of contacts performed')\n",
    "ax[1, 1].hist(data2[data2['pdays'] != 999]['pdays'],color = '#DC4405',alpha=0.7, edgecolor='white')\n",
    "ax[1, 1].hist(data1[data1['pdays'] != 999]['pdays'],color='#000000',alpha=0.5, edgecolor='white')\n",
    "ax[1, 1].title.set_text('Previous contact days')\n",
    "plt.figlegend((b1[0], b2[0]), ('Yes', 'No'),loc=\"right\",title = \"Term deposit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "ax.hist(data2['previous'],color = '#DC4405',alpha=0.7, edgecolor='white')\n",
    "ax.hist(data1['previous'],color='#000000',alpha=0.5, edgecolor='white')\n",
    "ax.title.set_text('Number of contacts performed previously')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore numerical features (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert target variable into numeric\n",
    "data.y = data.y.map({'no':0, 'yes':1}).astype('uint8')\n",
    "data_new.y.replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "print(data_new.shape)\n",
    "data_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Build correlation matrix\n",
    "corr = data.corr()\n",
    "corr.style.background_gradient(cmap='PuBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replacing values with binary ()\n",
    "data.contact = data.contact.map({'cellular': 1, 'telephone': 0, 'unknown': 0}).astype('uint8')\n",
    "data.loan = data.loan.map({'yes': 1, 'unknown': 0, 'no' : 0}).astype('uint8')\n",
    "data.housing = data.housing.map({'yes': 1, 'unknown': 0, 'no' : 0}).astype('uint8')\n",
    "data.default = data.default.map({'no': 1, 'unknown': 0, 'yes': 0}).astype('uint8')\n",
    "data.pdays = data.pdays.replace(999, 0) # replace with 0 if not contact\n",
    "data.previous = data.previous.apply(lambda x: 1 if x > 0 else 0).astype('uint8') # binary has contact or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# binary if were was an outcome of marketing campane\n",
    "data.poutcome.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.poutcome = data.poutcome.map({'unknown':0, 'failure':0, 'other':0, 'success':1}).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.age = np.log(data.age)\n",
    "\n",
    "# less space\n",
    "\n",
    "data.campaign = data.campaign.astype('uint8')\n",
    "data.pdays = data.pdays.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fucntion to One Hot Encoding\n",
    "def encode(data, col):\n",
    "    return pd.concat([data, pd.get_dummies(col, prefix=col.name)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot encoding of 3 variable\n",
    "data = encode(data, data.job)\n",
    "data = encode(data, data.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop tranfromed features\n",
    "data.drop(['job', 'month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Convert Duration Call into 5 category'''\n",
    "def duration(data):\n",
    "    data.loc[data['duration'] <= 102, 'duration'] = 1\n",
    "    data.loc[(data['duration'] > 102) & (data['duration'] <= 180)  , 'duration'] = 2\n",
    "    data.loc[(data['duration'] > 180) & (data['duration'] <= 319)  , 'duration'] = 3\n",
    "    data.loc[(data['duration'] > 319) & (data['duration'] <= 645), 'duration'] = 4\n",
    "    data.loc[data['duration']  > 645, 'duration'] = 5\n",
    "    return data\n",
    "duration(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treating Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save target variable before transformation\n",
    "y = data.y\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This imbalance has to treated so as to make sure that there is no bias in modeling. </br>\n",
    "Imbalance is generally treated in three ways.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictors = data.drop(['pdays'],axis=1)\n",
    "X = predictors.drop(['y'],axis=1)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Undersampling\n",
    "In this method, the majority category,</br>\n",
    "in this case 'no' category is randomly</br>\n",
    "sampled to match the size of the minority 'yes' category.</br>\n",
    "Remaining data of majority category is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_Usampled, y_Usampled = rus.fit_resample(X, y)\n",
    "pd.Series(y_Usampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Target encoding for two categorical feature '''\n",
    "# Create target encoder object\n",
    "target_encode = ce.target_encoder.TargetEncoder(cols=['marital', 'education']).fit(data, y)\n",
    "numeric_dataset = target_encode.transform(data)\n",
    "# drop target variable\n",
    "numeric_dataset.drop('y', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "## Random Oversampling\n",
    "In this method, the minority category 'no' is randomly sampled with replacement</br>\n",
    "to match the size of the majority 'no' category. Minority category entries will be repeated</br>\n",
    "many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_Osampled, y_Osampled = ros.fit_resample(X, y)\n",
    "pd.Series(y_Osampled).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - Synthetic Minority Oversampling Technique\n",
    "This is an oversampling technique in which instead of randomly repeating minority 'yes' category,<\\br>\n",
    "new entires are sythetically created maintaining the convexity of minority entry space.<\\br>\n",
    "Minority category will again match the majority category samples.<\\br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X, y)\n",
    "pd.Series(y_SMOTE).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Check numerical data set'''\n",
    "print(numeric_dataset.shape, y.shape)\n",
    "print(f'We observe {numeric_dataset.shape} rows  numerical features after transformation.'\n",
    "      f' Target variable shape is {y.shape} as expected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Split data on train and test'''\n",
    "# set global random state\n",
    "random_state = 11\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric_dataset, y, test_size=0.2, random_state=random_state)\n",
    "# collect excess data\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('check the shape of splitted train and test sets \\n', X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Build pipline of classifiers'''\n",
    "# set all CPU\n",
    "n_jobs = -1\n",
    "\n",
    "# LogisticRegression\n",
    "pipe_lr = Pipeline([('lr', LogisticRegression(\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_jobs,\n",
    "    max_iter=500))])\n",
    "\n",
    "# RandomForestClassifier\n",
    "pipe_rf = Pipeline([('rf', RandomForestClassifier(random_state=random_state,\n",
    "                                                  oob_score=True,\n",
    "                                                  n_jobs=n_jobs))])\n",
    "\n",
    "# KNeighborsClassifier\n",
    "pipe_knn = Pipeline([('knn', KNeighborsClassifier(n_jobs=n_jobs))])\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "pipe_dt = Pipeline([('dt', DecisionTreeClassifier(random_state=random_state,\n",
    "                                                  max_features='auto'))])\n",
    "# BaggingClassifier\n",
    "# note we use SGDClassifier as classier inside BaggingClassifier\n",
    "pipe_bag = Pipeline([('bag',BaggingClassifier(base_estimator=SGDClassifier(random_state=random_state,\n",
    "                                                                           n_jobs=n_jobs,\n",
    "                                                                           max_iter=1500),\n",
    "                                              random_state=random_state,\n",
    "                                              oob_score=True,\n",
    "                                              n_jobs=n_jobs))])\n",
    "\n",
    "# SGDClassifier\n",
    "pipe_sgd = Pipeline([('sgd', SGDClassifier(random_state=random_state,\n",
    "                                           n_jobs=n_jobs,\n",
    "                                           max_iter=1500))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Set parameters for Grid Search '''\n",
    "# set number\n",
    "cv = StratifiedKFold(shuffle=True,\n",
    "                     n_splits=5,\n",
    "                     random_state=random_state)\n",
    "# set for LogisticRegression\n",
    "grid_params_lr = [{\n",
    "                'lr__penalty': ['l2'],\n",
    "                'lr__C': [0.3, 0.6, 0.7],\n",
    "                'lr__solver': ['sag']\n",
    "                }]\n",
    "# set for RandomForestClassifier\n",
    "grid_params_rf = [{\n",
    "                'rf__criterion': ['entropy'],\n",
    "                'rf__min_samples_leaf': [80, 100],\n",
    "                'rf__max_depth': [25, 27],\n",
    "                'rf__min_samples_split': [3, 5],\n",
    "                'rf__n_estimators' : [60, 70]\n",
    "                }]\n",
    "# set for KNeighborsClassifier\n",
    "grid_params_knn = [{'knn__n_neighbors': [16,17,18]}]\n",
    "\n",
    "# set for DecisionTreeClassifier\n",
    "grid_params_dt = [{\n",
    "                'dt__max_depth': [8, 10],\n",
    "                'dt__min_samples_leaf': [1, 3, 5, 7]\n",
    "                  }]\n",
    "# set for BaggingClassifier\n",
    "grid_params_bag = [{'bag__n_estimators': [10, 15, 20]}]\n",
    "\n",
    "# set for SGDClassifier\n",
    "grid_params_sgd = [{\n",
    "                    'sgd__loss': ['log', 'huber'],\n",
    "                    'sgd__learning_rate': ['adaptive'],\n",
    "                    'sgd__eta0': [0.001, 0.01, 0.1],\n",
    "                    'sgd__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                    'sgd__alpha':[0.1, 1, 5, 10]\n",
    "                    }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''Grid search objects'''\n",
    "# for LogisticRegression\n",
    "gs_lr = GridSearchCV(pipe_lr,\n",
    "                     param_grid=grid_params_lr,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for RandomForestClassifier\n",
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid=grid_params_rf,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for KNeighborsClassifier\n",
    "gs_knn = GridSearchCV(pipe_knn,\n",
    "                      param_grid=grid_params_knn,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for DecisionTreeClassifier\n",
    "gs_dt = GridSearchCV(pipe_dt,\n",
    "                     param_grid=grid_params_dt,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for BaggingClassifier\n",
    "gs_bag = GridSearchCV(pipe_bag,\n",
    "                      param_grid=grid_params_bag,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "# for SGDClassifier\n",
    "gs_sgd = GridSearchCV(pipe_sgd,\n",
    "                      param_grid=grid_params_sgd,\n",
    "                     scoring='accuracy', cv=cv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# models that we iterate over\n",
    "look_for = [gs_lr, gs_rf, gs_knn, gs_dt, gs_bag, gs_sgd]\n",
    "# dict for later use\n",
    "model_dict = {\n",
    "    0:'Logistic_reg',\n",
    "    1:'RandomForest',\n",
    "    2:'Knn',\n",
    "    3:'DesionTree',\n",
    "    4:'Bagging with SGDClassifier',\n",
    "    5:'SGD Class'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def do_results_obtain(look_for, X_train, y_train,X_test, y_test):\n",
    "\n",
    "    ''' Function to iterate over models and obtain results'''\n",
    "\n",
    "    result_acc = {}\n",
    "    result_auc = {}\n",
    "    models = []\n",
    "\n",
    "    for index, model in enumerate(look_for):\n",
    "            start = time.time()\n",
    "            print()\n",
    "            print('+++++++ Start New Model ++++++++++++++++++++++')\n",
    "            print('Estimator is {}'.format(model_dict[index]))\n",
    "            model.fit(X_train, y_train)\n",
    "            print('---------------------------------------------')\n",
    "            print('best params {}'.format(model.best_params_))\n",
    "            print('best score is {}'.format(model.best_score_))\n",
    "            auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "            print('---------------------------------------------')\n",
    "            print('ROC_AUC is {} and accuracy rate is {}'.format(auc, model.score(X_test, y_test)))\n",
    "            end = time.time()\n",
    "            print('It lasted for {} sec'.format(round(end - start, 3)))\n",
    "            print('++++++++ End Model +++++++++++++++++++++++++++')\n",
    "            print()\n",
    "            print()\n",
    "            models.append(model.best_estimator_)\n",
    "            result_acc[index] = model.best_score_\n",
    "            result_auc[index] = auc\n",
    "    return (result_acc, result_auc, models)\n",
    "\n",
    "result_acc, result_auc, models = do_results_obtain(look_for, X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(model_dict.values(), result_acc.values(), c='r')\n",
    "plt.plot(model_dict.values(), result_auc.values(), c='b')\n",
    "plt.xlabel('Models')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Accouracy and ROC_AUC')\n",
    "plt.title('Result of Grid Search')\n",
    "plt.legend(['Accuracy', 'ROC_AUC'])\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Model performance during Grid Search \"\"\"\n",
    "pd.DataFrame(list(zip(model_dict.values(), result_acc.values(), result_auc.values())),\n",
    "                  columns=['Model', 'Accuracy_rate','Roc_auc_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def graph(model, X_train, y_train):\n",
    "    obb = []\n",
    "    est = list(range(5, 200, 5))\n",
    "    for i in tqdm(est):\n",
    "        random_forest = model(n_estimators=i, criterion='entropy', random_state=11, oob_score=True, n_jobs=-1, \\\n",
    "                           max_depth=25, min_samples_leaf=80, min_samples_split=3,)\n",
    "        random_forest.fit(X_train, y_train)\n",
    "        obb.append(random_forest.oob_score_)\n",
    "    print('max oob {} and number of estimators {}'.format(max(obb), est[np.argmax(obb)]))\n",
    "    plt.plot(est, obb)\n",
    "    plt.title('model')\n",
    "    plt.xlabel('number of estimators')\n",
    "    plt.ylabel('oob score')\n",
    "    plt.show()\n",
    "\n",
    "graph(RandomForestClassifier, X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Build graph for ROC_AUC '''\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, models[1].predict_proba(X_test)[:,1])\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=fpr,\n",
    "    y=tpr,\n",
    "    text=threshold,\n",
    "    fill='tozeroy',\n",
    "    name='ROC Curve')\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x=[0,1],\n",
    "    y=[0,1],\n",
    "    line={'color': 'red', 'width': 1, 'dash': 'dash'},\n",
    "    name='Baseline')\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='ROC Curve',\n",
    "    xaxis={'title': 'False Positive Rate'},\n",
    "    yaxis={'title': 'True Positive Rate'})\n",
    "\n",
    "fig = go.Figure(data, layout)\n",
    "fig.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "''' Build bar plot of feature importance of the best model '''\n",
    "\n",
    "def build_feature_importance(model, X_train, y_train):\n",
    "\n",
    "    models = RandomForestClassifier(criterion='entropy', random_state=11, oob_score=True, n_jobs=-1, \\\n",
    "                           max_depth=25, min_samples_leaf=80, min_samples_split=3, n_estimators=70)\n",
    "    models.fit(X_train, y_train)\n",
    "    data = pd.DataFrame(models.feature_importances_, X_train.columns, columns=[\"feature\"])\n",
    "    data = data.sort_values(by='feature', ascending=False).reset_index()\n",
    "    plt.figure(figsize=[6,6])\n",
    "    sns.barplot(x='index', y='feature', data=data[:10], palette=\"Blues_d\")\n",
    "    plt.title('Feature inportance of Random Forest after Grid Search')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "build_feature_importance(RandomForestClassifier, X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=7)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, y_train)\n",
    "model = tree.fit(X_SMOTE,y_SMOTE)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "forest = RandomForestClassifier(n_estimators= 1000,criterion=\"gini\", max_depth=5,min_samples_split = 0.4,min_samples_leaf=1, class_weight=\"balanced\")\n",
    "model = forest.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "pd.Series(y_pred).value_counts()\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "forest = RandomForestClassifier(n_estimators= 1000,criterion=\"gini\", max_depth=5,min_samples_split = 0.4,min_samples_leaf=1, class_weight=\"balanced\")\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, y_train)\n",
    "model = forest.fit(X_SMOTE,y_SMOTE)\n",
    "y_pred = model.predict(X_test)\n",
    "pd.Series(y_pred).value_counts()\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model = lm.LogisticRegression(random_state=0, solver='lbfgs',multi_class='auto',max_iter=1000).fit(X_train,y_train)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "fpr_imb, tpr_imb, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_imb = auc(fpr_imb, tpr_imb)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Imbalanced -\")\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n",
    "# Undersampled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_Usampled, y_Usampled = rus.fit_resample(X_train, y_train)\n",
    "model = lm.LogisticRegression(random_state=0, solver='lbfgs',multi_class='auto',max_iter=5000).fit(X_Usampled,y_Usampled)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "fpr_us, tpr_us, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_us = auc(fpr_us, tpr_us)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Random undersampled -\")\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n",
    "# Oversampled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_Osampled, y_Osampled = ros.fit_resample(X_train, y_train)\n",
    "model = lm.LogisticRegression(random_state=0, solver='lbfgs',multi_class='auto',max_iter=5000).fit(X_Osampled, y_Osampled)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "fpr_os, tpr_os, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_os = auc(fpr_os, tpr_os)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Random oversampled -\")\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n",
    "# SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "sm = SMOTE(random_state=0)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, y_train)\n",
    "model = lm.LogisticRegression(random_state=0, solver='lbfgs',multi_class='auto',max_iter=5000).fit(X_SMOTE,y_SMOTE)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "y_pred = y_pred[:,1]\n",
    "\n",
    "fpr_smote, tpr_smote, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_smote = auc(fpr_smote, tpr_smote)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"SMOTE -\")\n",
    "print(\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_imb, tpr_imb,\n",
    "         label='Imbalanced data ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc_imb),\n",
    "         color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot(fpr_us, tpr_us,\n",
    "         label='Undersampled data ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc_us),\n",
    "         color='blue', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.plot(fpr_os, tpr_os,\n",
    "         label='Random Oversampled data ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc_os),\n",
    "         color='darkred', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.plot(fpr_smote, tpr_smote,\n",
    "         label='SMOTE data ROC curve (area = {0:0.4f})'\n",
    "               ''.format(roc_auc_smote),\n",
    "         color='darkgreen', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.00])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_SMOTE, y_SMOTE, test_size=0.3)\n",
    "svm = SVC(kernel='linear')\n",
    "model = svm.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Linear kernel- \",\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n",
    "fpr_linear, tpr_linear, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_linear = auc(fpr_linear, tpr_linear)\n",
    "sm = SMOTE(random_state=0)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_SMOTE, y_SMOTE, test_size=0.3)\n",
    "svm = SVC(kernel='rbf')\n",
    "model = svm.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Guassian kernel- \",\"Precision: \",round(precision_score(y_test,y_pred),2),\"Recall: \",round(recall_score(y_test,y_pred),2))\n",
    "fpr_rbf, tpr_rbf, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc_rbf = auc(fpr_rbf, tpr_rbf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
